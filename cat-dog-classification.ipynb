{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7186543,"sourceType":"datasetVersion","datasetId":1840863}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-07-24T22:49:07.008659Z","iopub.execute_input":"2024-07-24T22:49:07.009061Z","iopub.status.idle":"2024-07-24T22:49:07.015532Z","shell.execute_reply.started":"2024-07-24T22:49:07.009018Z","shell.execute_reply":"2024-07-24T22:49:07.014611Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    model = Sequential([\n        Conv2D(128, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n        MaxPooling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu'),\n        MaxPooling2D((2, 2)),\n        Conv2D(32, (3, 3), activation='relu'),\n        MaxPooling2D((2, 2)),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(256, activation='relu'),\n        Dropout(0.5),\n        Dense(1, activation='sigmoid')\n    ])\n    \n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-07-24T23:03:17.856043Z","iopub.execute_input":"2024-07-24T23:03:17.856394Z","iopub.status.idle":"2024-07-24T23:03:17.863535Z","shell.execute_reply.started":"2024-07-24T23:03:17.856367Z","shell.execute_reply":"2024-07-24T23:03:17.862557Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('/kaggle/input/cat-dog-images-for-classification/cat_dog.csv')\ndf['labels'] = df['labels'].apply(lambda x: 'cat' if x == 0 else 'dog')\n\n# Split the dataset\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Image Data Generators\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    directory='/kaggle/input/cat-dog-images-for-classification/cat_dog', \n    x_col='image', \n    y_col='labels', \n    target_size=(128, 128), \n    class_mode='binary', \n    batch_size=32\n)\n\nval_generator = val_datagen.flow_from_dataframe(\n    val_df, \n    directory='/kaggle/input/cat-dog-images-for-classification/cat_dog', \n    x_col='image', \n    y_col='labels', \n    target_size=(128, 128), \n    class_mode='binary', \n    batch_size=32\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T22:53:17.951749Z","iopub.execute_input":"2024-07-24T22:53:17.952130Z","iopub.status.idle":"2024-07-24T22:53:29.266986Z","shell.execute_reply.started":"2024-07-24T22:53:17.952099Z","shell.execute_reply":"2024-07-24T22:53:29.266239Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Found 20000 validated image filenames belonging to 2 classes.\nFound 5000 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = create_model()\nhistory = model.fit(\n    train_generator, \n    epochs=10, \n    validation_data=val_generator\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T23:03:28.108924Z","iopub.execute_input":"2024-07-24T23:03:28.110046Z","iopub.status.idle":"2024-07-24T23:11:45.996847Z","shell.execute_reply.started":"2024-07-24T23:03:28.109975Z","shell.execute_reply":"2024-07-24T23:11:45.995881Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m  4/625\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 51ms/step - accuracy: 0.5215 - loss: 0.7840","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1721862212.941243     132 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5469 - loss: 0.6870","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1721862252.784387     135 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 79ms/step - accuracy: 0.5470 - loss: 0.6870 - val_accuracy: 0.6344 - val_loss: 0.6447\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1721862262.201905     132 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 79ms/step - accuracy: 0.6636 - loss: 0.6147 - val_accuracy: 0.6758 - val_loss: 0.5934\nEpoch 3/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 78ms/step - accuracy: 0.7394 - loss: 0.5249 - val_accuracy: 0.7526 - val_loss: 0.5105\nEpoch 4/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 79ms/step - accuracy: 0.8081 - loss: 0.4202 - val_accuracy: 0.7428 - val_loss: 0.5371\nEpoch 5/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 80ms/step - accuracy: 0.8796 - loss: 0.2861 - val_accuracy: 0.7646 - val_loss: 0.5979\nEpoch 6/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 78ms/step - accuracy: 0.9446 - loss: 0.1431 - val_accuracy: 0.7504 - val_loss: 0.9395\nEpoch 7/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 77ms/step - accuracy: 0.9701 - loss: 0.0853 - val_accuracy: 0.7482 - val_loss: 1.0050\nEpoch 8/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 77ms/step - accuracy: 0.9875 - loss: 0.0387 - val_accuracy: 0.7422 - val_loss: 1.4716\nEpoch 9/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 77ms/step - accuracy: 0.9927 - loss: 0.0277 - val_accuracy: 0.7386 - val_loss: 1.4165\nEpoch 10/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 78ms/step - accuracy: 0.9890 - loss: 0.0297 - val_accuracy: 0.7414 - val_loss: 1.5133\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model\nloss, accuracy = model.evaluate(val_generator)\nprint(f'Accuracy on raw images: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-07-24T23:11:56.777771Z","iopub.execute_input":"2024-07-24T23:11:56.778145Z","iopub.status.idle":"2024-07-24T23:12:06.874267Z","shell.execute_reply.started":"2024-07-24T23:11:56.778115Z","shell.execute_reply":"2024-07-24T23:12:06.873352Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7468 - loss: 1.3687\nAccuracy on raw images: 0.7414000034332275\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ----------------------- After Prerocessing ---------------------","metadata":{}},{"cell_type":"code","source":"def apply_filters(image):\n    # Convert to array\n    image = np.array(image)\n    \n    # Apply a sharpening filter\n    kernel = np.array([[0, -1, 0], \n                       [-1, 5,-1],\n                       [0, -1, 0]])\n    image = cv2.filter2D(src=image, ddepth=-1, kernel=kernel)\n    \n    return image\n\n# Image Data Generators with augmentation and custom filter\ntrain_datagen_aug = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    preprocessing_function=apply_filters\n)\n\ntrain_generator_aug = train_datagen_aug.flow_from_dataframe(\n    train_df, \n    directory='/kaggle/input/cat-dog-images-for-classification/cat_dog', \n    x_col='image', \n    y_col='labels', \n    target_size=(128, 128), \n    class_mode='binary', \n    batch_size=32\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T23:12:12.636789Z","iopub.execute_input":"2024-07-24T23:12:12.637265Z","iopub.status.idle":"2024-07-24T23:12:17.225174Z","shell.execute_reply.started":"2024-07-24T23:12:12.637232Z","shell.execute_reply":"2024-07-24T23:12:17.224426Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Found 20000 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create and train the model on augmented data\nmodel_aug = create_model()\nhistory_aug = model_aug.fit(\n    train_generator_aug, \n    epochs=10, \n    validation_data=val_generator\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-24T23:12:57.311750Z","iopub.execute_input":"2024-07-24T23:12:57.312425Z","iopub.status.idle":"2024-07-24T23:35:10.580269Z","shell.execute_reply.started":"2024-07-24T23:12:57.312390Z","shell.execute_reply":"2024-07-24T23:35:10.579252Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  1/625\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54:47\u001b[0m 5s/step - accuracy: 0.5938 - loss: 0.7052","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1721862783.057637     132 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m624/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.5433 - loss: 0.6862","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1721862904.614511     135 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 210ms/step - accuracy: 0.5434 - loss: 0.6861 - val_accuracy: 0.6232 - val_loss: 0.6531\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1721862914.111829     133 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 209ms/step - accuracy: 0.6847 - loss: 0.5932 - val_accuracy: 0.5638 - val_loss: 0.7316\nEpoch 3/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 209ms/step - accuracy: 0.7674 - loss: 0.4847 - val_accuracy: 0.6658 - val_loss: 0.5929\nEpoch 4/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 213ms/step - accuracy: 0.8021 - loss: 0.4381 - val_accuracy: 0.6790 - val_loss: 0.5865\nEpoch 5/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 213ms/step - accuracy: 0.8060 - loss: 0.4225 - val_accuracy: 0.6332 - val_loss: 0.6561\nEpoch 6/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 211ms/step - accuracy: 0.8271 - loss: 0.3896 - val_accuracy: 0.6752 - val_loss: 0.5973\nEpoch 7/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 210ms/step - accuracy: 0.8415 - loss: 0.3614 - val_accuracy: 0.7294 - val_loss: 0.5390\nEpoch 8/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 212ms/step - accuracy: 0.8466 - loss: 0.3543 - val_accuracy: 0.6502 - val_loss: 0.6723\nEpoch 9/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 210ms/step - accuracy: 0.8548 - loss: 0.3335 - val_accuracy: 0.6692 - val_loss: 0.6029\nEpoch 10/10\n\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 209ms/step - accuracy: 0.8657 - loss: 0.3187 - val_accuracy: 0.7396 - val_loss: 0.5085\n","output_type":"stream"}]},{"cell_type":"code","source":"loss_aug, accuracy_aug = model_aug.evaluate(val_generator)\nprint(f'Accuracy on processed images: {accuracy_aug}')","metadata":{"execution":{"iopub.status.busy":"2024-07-24T23:38:32.344139Z","iopub.execute_input":"2024-07-24T23:38:32.344787Z","iopub.status.idle":"2024-07-24T23:38:42.006691Z","shell.execute_reply.started":"2024-07-24T23:38:32.344755Z","shell.execute_reply":"2024-07-24T23:38:42.005785Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.7401 - loss: 0.5038\nAccuracy on processed images: 0.7396000027656555\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'Accuracy on raw images: {accuracy}')\nprint(f'Accuracy on processed images: {accuracy_aug}')","metadata":{"execution":{"iopub.status.busy":"2024-07-24T23:38:43.807752Z","iopub.execute_input":"2024-07-24T23:38:43.808123Z","iopub.status.idle":"2024-07-24T23:38:43.813246Z","shell.execute_reply.started":"2024-07-24T23:38:43.808093Z","shell.execute_reply":"2024-07-24T23:38:43.812166Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Accuracy on raw images: 0.7414000034332275\nAccuracy on processed images: 0.7396000027656555\n","output_type":"stream"}]},{"cell_type":"markdown","source":"From output \n- actual image without any preprocessing is high accuracy than processed image.\nbecause actual image high quailty and don't need to processed.","metadata":{}}]}